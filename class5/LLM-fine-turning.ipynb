{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60bc6e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./.venv/lib/python3.10/site-packages (4.55.2)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./.venv/lib/python3.10/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.10/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.10/site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.10/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.10/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.8)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6f27ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b62fe03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float16 if device == \"mps\" else torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67027143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.80s/it]\n",
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is Scott Lai? He is a Chinese-American actor, singer, and dancer who was born on January 29, 1995, in Los Angeles, California. He began his acting career at the age of six, starring in Disney Channel's \"The Suite Life of Zack & Cody\" and later in the animated series \"Kim Possible.\" In addition to acting, Scott has also been involved in singing and dancing, performing in various music videos and commercials.\n",
      "\n",
      "Scott Lai has been featured in several popular TV shows and movies, including \"The Flash,\" \"Riverdale,\" \"Gossip Girl,\" and \"The Secret Life of the American Teenager.\" He has also released several singles and EPs as a solo artist under various record labels.\n",
      "\n",
      "In recent years, Scott has gained popularity for his performances in films such as \"The Last Witch Hunter\" (2015), \"Crimson Peak\" (2015), and \"Kingsman: The Secret Service\" (2014). He has also appeared in the TV series \"Black Lightning\" and \"Younger.\"\n",
      "\n",
      "Scott Lai continues to be active in the entertainment industry, both as an actor and a musician, and has established himself as a versatile performer with a diverse range of skills.\n"
     ]
    }
   ],
   "source": [
    "ask_llm = pipeline(\n",
    "  task=\"text-generation\",\n",
    "  model=\"Qwen/Qwen2.5-3B-Instruct\",\n",
    "  device=device,\n",
    "  torch_dtype=dtype\n",
    ")\n",
    "\n",
    "print(ask_llm(\"Who is Scott Lai?\")[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145dc2e4",
   "metadata": {},
   "source": [
    "As you can see here, the model has no idea who I am from above response.\n",
    "\n",
    "Let's cook it!\n",
    "\n",
    "First, let's teach the model who I am. Here you can use your personal data to generate the exact format you will use for fine-turning base on your own data. You can use ChatGPT for this, just ask it to transfer your resume into the trainable json format with \"prompt\" and \"completion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "869c27e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'completion'],\n",
       "        num_rows: 122\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data \n",
    "from datasets import load_dataset\n",
    "\n",
    "raw_data = load_dataset('json', data_files = \"scott_lai_resume_train.json\")\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3e9dc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'What is Scott Lai’s profession?',\n",
       " 'completion': 'AI Engineer and Data Scientist.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f13cf6e",
   "metadata": {},
   "source": [
    "As you can see, here we return with the long text, but for fine-tuning we need the data to be small and precise chunks, more like here we apply the tokenization to take the text and split it into smaller chunks. Each chunk is called a token and it the smallest unit of meaning that LLMs work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da03887b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 122/122 [00:00<00:00, 6332.04 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is Scott Lai’s profession?\n",
      "AI Engineer and Data Scientist.\n",
      "How many years of experience does Scott Lai have in generative AI and LLM solutions?\n",
      "Over 5 years.\n",
      "What infrastructures is Scott Lai skilled in designing and optimizing?\n",
      "Scalable ML infrastructures using PyTorch, Hugging Face, and FastAPI on AWS.\n",
      "What type of workflows is Scott Lai experienced in building?\n",
      "End-to-end pipelines, scalable microservices, and ETL workflows.\n",
      "What collaboration experience does Scott Lai have?\n",
      "Proven track record in cross-functional collaboration and implementing ML and data engineering best practices.\n",
      "Which skill in Programming & Scripting does Scott Lai have?\n",
      "Python\n",
      "Which skill in Programming & Scripting does Scott Lai have?\n",
      "Rust\n",
      "Which skill in Programming & Scripting does Scott Lai have?\n",
      "Node.js\n",
      "Which skill in Programming & Scripting does Scott Lai have?\n",
      "HTML\n",
      "Which skill in Programming & Scripting does Scott Lai have?\n",
      "CSS\n",
      "Which skill in Programming & Scripting does Scott Lai have?\n",
      "JavaScript\n",
      "Which skill in Programming & Scripting does Scott Lai have?\n",
      "R\n",
      "Which skill in Programming & Scripting does Scott Lai have?\n",
      "Bash\n",
      "Which skill in Programming & Scripting does Scott Lai have?\n",
      "GoLang\n",
      "Which skill in Machine Learning & AI does Scott Lai have?\n",
      "Machine Learning\n",
      "Which skill in Machine Learning & AI does Scott Lai have?\n",
      "Deep Learning\n",
      "Which skill in Machine Learning & AI does Scott Lai have?\n",
      "Reinforcement Learning\n",
      "Which skill in Machine Learning & AI does Scott Lai have?\n",
      "TensorFlow\n",
      "Which skill in Machine Learning & AI does Scott Lai have?\n",
      "PyTorch\n",
      "Which skill in Machine Learning & AI does Scott Lai have?\n",
      "Scikit Learn\n",
      "Which skill in Machine Learning & AI does Scott Lai have?\n",
      "Hugging Face\n",
      "Which skill in Machine Learning & AI does Scott Lai have?\n",
      "LangChain\n",
      "Which skill in Machine Learning & AI does Scott Lai have?\n",
      "LlamaIndex\n",
      "Which skill in Machine Learning & AI does Scott Lai have?\n",
      "Generative AI\n",
      "Which skill in Machine Learning & AI does Scott Lai have?\n",
      "LangGraph\n",
      "Which skill in ML Infrastructure & Optimization does Scott Lai have?\n",
      "LLM Serving Frameworks\n",
      "Which skill in ML Infrastructure & Optimization does Scott Lai have?\n",
      "ETL Pipelines\n",
      "Which skill in ML Infrastructure & Optimization does Scott Lai have?\n",
      "TensorRT\n",
      "Which skill in ML Infrastructure & Optimization does Scott Lai have?\n",
      "Deepspeed\n",
      "Which skill in Cloud & DevOps does Scott Lai have?\n",
      "AWS\n",
      "Which skill in Cloud & DevOps does Scott Lai have?\n",
      "GCP\n",
      "Which skill in Cloud & DevOps does Scott Lai have?\n",
      "Azure\n",
      "Which skill in Cloud & DevOps does Scott Lai have?\n",
      "Docker\n",
      "Which skill in Cloud & DevOps does Scott Lai have?\n",
      "Kubernetes\n",
      "Which skill in Cloud & DevOps does Scott Lai have?\n",
      "Beanstalk\n",
      "Which skill in Cloud & DevOps does Scott Lai have?\n",
      "Terraform\n",
      "Which skill in Cloud & DevOps does Scott Lai have?\n",
      "S3\n",
      "Which skill in Cloud & DevOps does Scott Lai have?\n",
      "EC2\n",
      "Which skill in Web & API Development does Scott Lai have?\n",
      "Flask\n",
      "Which skill in Web & API Development does Scott Lai have?\n",
      "Django\n",
      "Which skill in Web & API Development does Scott Lai have?\n",
      "FastAPI\n",
      "Which skill in Web & API Development does Scott Lai have?\n",
      "API Design\n",
      "Which skill in Tools & Methodologies does Scott Lai have?\n",
      "Git\n",
      "Which skill in Tools & Methodologies does Scott Lai have?\n",
      "CI/CD\n",
      "Which skill in Tools & Methodologies does Scott Lai have?\n",
      "Unit Testing\n",
      "Which skill in Tools & Methodologies does Scott Lai have?\n",
      "Integration Testing\n",
      "Which skill in Tools & Methodologies does Scott Lai have?\n",
      "DataDog\n",
      "Which skill in Tools & Methodologies does Scott Lai have?\n",
      "Tableau\n",
      "Which skill in Tools & Methodologies does Scott Lai have?\n",
      "Spark\n",
      "Which skill in Tools & Methodologies does Scott Lai have?\n",
      "Hadoop\n",
      "Which skill in Tools & Methodologies does Scott Lai have?\n",
      "Stable Diffusion\n",
      "Which skill in Tools & Methodologies does Scott Lai have?\n",
      "Claude code\n",
      "Which skill in Tools & Methodologies does Scott Lai have?\n",
      "Midjourney\n",
      "Which skill in Tools & Methodologies does Scott Lai have?\n",
      "CodeWhisperer\n",
      "Which skill in Tools & Methodologies does Scott Lai have?\n",
      "OCR\n",
      "Which skill in Tools & Methodologies does Scott Lai have?\n",
      "Cursor\n",
      "Which skill in Tools & Methodologies does Scott Lai have?\n",
      "taskMaster\n",
      "Which skill in Tools & Methodologies does Scott Lai have?\n",
      "Computer Vision\n",
      "What did Scott Lai accomplish at BlueberryAI?\n",
      "Developed production-ready AI-driven agents and advanced RAG models for legal analysis on AWS.\n",
      "What did Scott Lai accomplish at BlueberryAI?\n",
      "Engineered and optimized data pipelines using AWS and Databricks.\n",
      "What did Scott Lai accomplish at BlueberryAI?\n",
      "Collaborated with cross-functional teams to address legal and regulatory compliance.\n",
      "What did Scott Lai accomplish at BlueberryAI?\n",
      "Communicated model metrics clearly to stakeholders.\n",
      "What did Scott Lai accomplish at BlueberryAI?\n",
      "Enhanced AI models for legal identification by integrating real-time analysis features into client-facing apps.\n",
      "What did Scott Lai contribute at ScholarAI?\n",
      "Designed and deployed a production-grade RAG system using LangChain and AWS DynamoDB.\n",
      "What did Scott Lai contribute at ScholarAI?\n",
      "Improved search accuracy by 35% through RAG optimization.\n",
      "What did Scott Lai contribute at ScholarAI?\n",
      "Engineered an AI-driven document processing pipeline handling 10,000+ daily requests with 98% accuracy.\n",
      "What did Scott Lai contribute at ScholarAI?\n",
      "Applied OCR techniques with optimized Python solutions.\n",
      "What did Scott Lai contribute at ScholarAI?\n",
      "Optimized custom LLM models achieving 17% better performance than ChatGPT and Claude 3.5.\n",
      "What did Scott Lai contribute at ScholarAI?\n",
      "Implemented a distributed multi-agent LLM architecture with FastAPI and React.\n",
      "What did Scott Lai contribute at ScholarAI?\n",
      "Supported over 500 concurrent users with the system.\n",
      "What did Scott Lai contribute at ScholarAI?\n",
      "Constructed scalable ETL pipelines with Apache Spark and Airflow.\n",
      "What did Scott Lai contribute at ScholarAI?\n",
      "Processed over 2TB of data efficiently in ScholarAI pipelines.\n",
      "What did Scott Lai contribute at ScholarAI?\n",
      "Integrated CI/CD best practices into ML model operations.\n",
      "What achievement did Scott Lai have at Ember Learning?\n",
      "Developed DeapLearning, an AI-powered tutoring platform with neural TTS.\n",
      "What achievement did Scott Lai have at Ember Learning?\n",
      "Served over 120,000 K-12 learners with DeapLearning.\n",
      "What achievement did Scott Lai have at Ember Learning?\n",
      "Directed a 13-person team across engineering, ML, and education.\n",
      "What achievement did Scott Lai have at Ember Learning?\n",
      "Launched a workshop builder and rubric grader reducing teacher workload by 60%.\n",
      "What achievement did Scott Lai have at Ember Learning?\n",
      "Architected a FERPA-secure LangChain-GPT-40 stack on AWS for 500+ concurrent users.\n",
      "What achievement did Scott Lai have at Ember Learning?\n",
      "Enhanced customer satisfaction through RLHF tuning.\n",
      "What achievement did Scott Lai have at Ember Learning?\n",
      "Expanded AP course offerings with reinforcement learning from human feedback.\n",
      "What achievement did Scott Lai have at Ember Learning?\n",
      "Formulated presentations that secured $1.2M in seed funding.\n",
      "What did Scott Lai do at Duke University?\n",
      "Collaborated with Hugging Face on LLM development using Rust Candle.\n",
      "What did Scott Lai do at Duke University?\n",
      "Managed AWS and Azure cloud research projects.\n",
      "What did Scott Lai do at Duke University?\n",
      "Led AWS Cloud Club with over 200 students.\n",
      "What did Scott Lai do at Duke University?\n",
      "Designed technical curricula for advanced AI and software development.\n",
      "What did Scott Lai do at Duke University?\n",
      "Provided mentorship to students in ML and scalable system design.\n",
      "What was Scott Lai’s contribution at Spigot, Inc.?\n",
      "Developed AI tools using ML and DL to enhance company operations.\n",
      "What was Scott Lai’s contribution at Spigot, Inc.?\n",
      "Conducted Big Data research with R for insights and trends.\n",
      "What was Scott Lai’s contribution at Spigot, Inc.?\n",
      "Explored Blockchain applications in FinTech.\n",
      "What was Scott Lai’s contribution at Spigot, Inc.?\n",
      "Enhanced transactional security with Blockchain solutions.\n",
      "What was Scott Lai’s contribution at Spigot, Inc.?\n",
      "Collaborated on FinTech projects with scalable ML methodologies.\n",
      "What did Scott Lai achieve at IUNISPACE?\n",
      "Led a data analysis team designing 12 quantitative trading algorithms.\n",
      "What did Scott Lai achieve at IUNISPACE?\n",
      "Helped the firm earn $2M in China's A-share market with ML trading strategies.\n",
      "What did Scott Lai achieve at IUNISPACE?\n",
      "Designed and deployed three data intelligence platforms for banking, real estate, and distressed assets.\n",
      "What did Scott Lai achieve at IUNISPACE?\n",
      "Saved clients $50M in labor and efficiency costs across 7+ corporations.\n",
      "What did Scott Lai achieve at IUNISPACE?\n",
      "Led simulation analysis of satellite remote sensing data for rocket and satellite launch.\n",
      "What did Scott Lai achieve at IUNISPACE?\n",
      "Integrated satellite imagery, GIS, and mobility data with financial analytics.\n",
      "What did Scott Lai achieve at IUNISPACE?\n",
      "Enhanced trading strategies with alternative data sources.\n",
      "What did Scott Lai achieve at IUNISPACE?\n",
      "Directed multidisciplinary teams in ML-driven solutions.\n",
      "What accomplishment did Scott Lai make at J.P. Morgan?\n",
      "Built predictive analytics models reducing loan default rates by 13%.\n",
      "What accomplishment did Scott Lai make at J.P. Morgan?\n",
      "Engineered scalable ETL pipelines and automated reporting systems.\n",
      "What accomplishment did Scott Lai make at J.P. Morgan?\n",
      "Implemented NLP solutions for transaction monitoring and fraud detection.\n",
      "What accomplishment did Scott Lai make at J.P. Morgan?\n",
      "Conducted analysis on customer behavior and transaction data.\n",
      "What accomplishment did Scott Lai make at J.P. Morgan?\n",
      "Presented technical findings to leadership with actionable recommendations.\n",
      "What is Scott Lai’s educational background?\n",
      "Earned a Master of Science in Interdisciplinary Data Science from Duke University.\n",
      "What is Scott Lai’s educational background?\n",
      "Studied Statistical Modeling, Data Engineering, NLP, Data Analysis in Cloud, and Machine Learning at Duke.\n",
      "What is Scott Lai’s educational background?\n",
      "Earned a Bachelor of Science in Statistics and Economics from University of Wisconsin-Madison.\n",
      "What is Scott Lai’s educational background?\n",
      "Studied Calculus, Linear Regression, Data Visualization, and Machine Learning in Python at UW-Madison.\n",
      "What is a lesson or contribution from Scott Lai’s ScholarAI patent project?\n",
      "Developed an AI-powered legal assistant for patent prosecution with Wilson Sonsini.\n",
      "What is a lesson or contribution from Scott Lai’s ScholarAI patent project?\n",
      "Built multi-agent system using FastAPI and LangChain.\n",
      "What is a lesson or contribution from Scott Lai’s ScholarAI patent project?\n",
      "Integrated USPTO data for claim drafting and prior art analysis.\n",
      "What is a lesson or contribution from Scott Lai’s ScholarAI patent project?\n",
      "Implemented backend handling 10,000+ documents daily with 98% accuracy.\n",
      "What is a lesson or contribution from Scott Lai’s ScholarAI patent project?\n",
      "Designed 4-panel interface mimicking attorney workflows.\n",
      "What is a lesson or contribution from Scott Lai’s ScholarAI patent project?\n",
      "Learned that overfitting to single-user workflows reduces adoption.\n",
      "What is a lesson or contribution from Scott Lai’s ScholarAI patent project?\n",
      "Recognized need for model tuning for domain-specific legal writing styles.\n",
      "What is a lesson or contribution from Scott Lai’s ScholarAI patent project?\n",
      "Identified trust deficit due to hallucinations and lack of explainability.\n",
      "What is a lesson or contribution from Scott Lai’s ScholarAI patent project?\n",
      "Gained lessons in human-AI interface design and iteration from feedback.\n",
      "Which cloud platforms is Scott Lai experienced with?\n",
      "AWS, GCP, and Azure.\n",
      "Which containerization and orchestration tools does Scott Lai use?\n",
      "Docker and Kubernetes.\n",
      "Which visualization tools has Scott Lai worked with?\n",
      "Tableau and Hadoop ecosystem tools.\n",
      "Which generative image models has Scott Lai used?\n",
      "Stable Diffusion and Midjourney.\n",
      "What programming languages does Scott Lai know besides Python?\n",
      "Rust, Node.js, JavaScript, R, Bash, GoLang, HTML, and CSS.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-3B-Instruct\"\n",
    ")\n",
    "def preprocess(sample):\n",
    "    sample = sample['prompt']+ '\\n' + sample['completion']\n",
    "    print(sample)\n",
    "    tokenized = tokenizer(\n",
    "        sample,\n",
    "        max_length = 128,\n",
    "        truncation = True,\n",
    "        padding = \"max_length\"    \n",
    "    )\n",
    "\n",
    "    tokenized['labels'] = tokenized['input_ids'].copy()\n",
    "    return tokenized\n",
    "data = raw_data.map(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6aae75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'completion', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 122\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(data['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436ab97f",
   "metadata": {},
   "source": [
    "## LoRA\n",
    "\n",
    "now, let's move into the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90228ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7c30e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "    device_map = device,\n",
    "    torch_dtype = torch.float16\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig (\n",
    "    \n",
    "    task_type = TaskType.CAUSAL_LM, \n",
    "    target_modules=['q_proj', \"k_proj\", \"v_proj\"]\n",
    ")\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33200b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    num_train_epochs = 10, # we will go throught the dataset from start to finish 10 times\n",
    "    learning_rate=0.001, \n",
    "    logging_steps = 25, # we want to see the result in every 25 steps it runs \n",
    "    fp16 = False # float point set to 16 to speed it up, set to \"True\" if you are on GPU\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    args = train_args,\n",
    "    model = model, \n",
    "    train_dataset=data[\"train\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b17f16de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottlai/Library/Mobile Documents/com~apple~CloudDocs/Desktop/work/inferenceAI/class5/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 07:41, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.352000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.370400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.234400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.191900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.162700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.133500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=160, training_loss=0.5460465855896472, metrics={'train_runtime': 463.458, 'train_samples_per_second': 2.632, 'train_steps_per_second': 0.345, 'total_flos': 2602200748523520.0, 'train_loss': 0.5460465855896472, 'epoch': 10.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed1aafcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./my-qwen/tokenizer_config.json',\n",
       " './my-qwen/special_tokens_map.json',\n",
       " './my-qwen/chat_template.jinja',\n",
       " './my-qwen/vocab.json',\n",
       " './my-qwen/merges.txt',\n",
       " './my-qwen/added_tokens.json',\n",
       " './my-qwen/tokenizer.json')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "trainer.save_model(\"./my-qwen\")\n",
    "tokenizer.save_pretrained(\"./my-qwen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7449af4",
   "metadata": {},
   "source": [
    "Now let's test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71e8b4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.28it/s]\n",
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is Scott Lai? A Data Engineer based in Los Angeles, CA.\n"
     ]
    }
   ],
   "source": [
    "ask_llm = pipeline(\n",
    "  task=\"text-generation\",\n",
    "  model=\"./my-qwen\",\n",
    "  tokenizer='./my-qwen',\n",
    "  device=device,\n",
    "  torch_dtype=dtype\n",
    ")\n",
    "\n",
    "print(ask_llm(\"Who is Scott Lai?\")[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ef1abc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
